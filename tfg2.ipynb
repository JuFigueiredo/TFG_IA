{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('myenv': conda)",
   "display_name": "Python 3.7.9 64-bit ('myenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "744af946de99698ec7e9e62d478fe8770259701214259cb086f1ba68c8045328"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Evaluation: Polynomial kernel\n              precision    recall  f1-score   support\n\n           1       0.31      1.00      0.48       496\n           2       0.00      0.00      0.00       471\n           3       0.00      0.00      0.00       420\n           4       0.91      0.65      0.76       508\n           5       0.75      0.92      0.83       556\n           6       1.00      0.98      0.99       545\n           7       0.00      0.00      0.00        23\n           8       0.00      0.00      0.00        10\n           9       0.00      0.00      0.00        32\n          10       0.00      0.00      0.00        25\n          11       0.00      0.00      0.00        49\n          12       0.00      0.00      0.00        27\n\n    accuracy                           0.59      3162\n   macro avg       0.25      0.30      0.25      3162\nweighted avg       0.50      0.59      0.51      3162\n\nEvaluation: RBF kernel\n              precision    recall  f1-score   support\n\n           1       0.96      0.99      0.98       496\n           2       0.95      0.97      0.96       471\n           3       0.99      0.95      0.97       420\n           4       0.97      0.90      0.93       508\n           5       0.92      0.98      0.95       556\n           6       1.00      1.00      1.00       545\n           7       0.95      0.83      0.88        23\n           8       0.91      1.00      0.95        10\n           9       0.70      0.66      0.68        32\n          10       0.73      0.76      0.75        25\n          11       0.71      0.73      0.72        49\n          12       0.74      0.63      0.68        27\n\n    accuracy                           0.95      3162\n   macro avg       0.88      0.87      0.87      3162\nweighted avg       0.95      0.95      0.95      3162\n\nEvaluation: Sigmoid kernel\n              precision    recall  f1-score   support\n\n           1       0.91      0.99      0.95       496\n           2       0.86      0.94      0.90       471\n           3       0.98      0.85      0.91       420\n           4       0.88      0.76      0.82       508\n           5       0.81      0.91      0.86       556\n           6       1.00      1.00      1.00       545\n           7       0.00      0.00      0.00        23\n           8       0.00      0.00      0.00        10\n           9       0.00      0.00      0.00        32\n          10       0.52      0.96      0.68        25\n          11       0.46      0.73      0.56        49\n          12       0.00      0.00      0.00        27\n\n    accuracy                           0.88      3162\n   macro avg       0.53      0.60      0.56      3162\nweighted avg       0.87      0.88      0.87      3162\n\nEvaluation: Linear kernel\n              precision    recall  f1-score   support\n\n           1       0.96      0.99      0.98       496\n           2       0.98      0.97      0.97       471\n           3       0.99      0.98      0.98       420\n           4       0.96      0.89      0.92       508\n           5       0.91      0.97      0.94       556\n           6       1.00      1.00      1.00       545\n           7       0.95      0.78      0.86        23\n           8       0.91      1.00      0.95        10\n           9       0.58      0.66      0.62        32\n          10       0.75      0.72      0.73        25\n          11       0.70      0.65      0.67        49\n          12       0.72      0.67      0.69        27\n\n    accuracy                           0.95      3162\n   macro avg       0.87      0.86      0.86      3162\nweighted avg       0.95      0.95      0.95      3162\n\nFitting 10 folds for each of 9 candidates, totalling 90 fits\n[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed: 24.1min\n[Parallel(n_jobs=2)]: Done  90 out of  90 | elapsed: 45.5min finished\n{&#39;C&#39;: 100, &#39;gamma&#39;: 0.001, &#39;kernel&#39;: &#39;rbf&#39;}\n              precision    recall  f1-score   support\n\n           1       0.95      0.99      0.97       496\n           2       0.98      0.96      0.97       471\n           3       0.99      0.97      0.98       420\n           4       0.96      0.90      0.93       508\n           5       0.91      0.97      0.94       556\n           6       1.00      1.00      1.00       545\n           7       1.00      0.83      0.90        23\n           8       0.91      1.00      0.95        10\n           9       0.68      0.78      0.72        32\n          10       0.70      0.76      0.73        25\n          11       0.76      0.69      0.72        49\n          12       0.73      0.59      0.65        27\n\n    accuracy                           0.95      3162\n   macro avg       0.88      0.87      0.87      3162\nweighted avg       0.95      0.95      0.95      3162\n\n[[493   0   3   0   0   0   0   0   0   0   0   0]\n [ 20 451   0   0   0   0   0   0   0   0   0   0]\n [  5   9 406   0   0   0   0   0   0   0   0   0]\n [  0   1   0 455  51   0   0   1   0   0   0   0]\n [  0   0   0  14 542   0   0   0   0   0   0   0]\n [  0   0   0   0   0 545   0   0   0   0   0   0]\n [  0   1   0   2   0   0  19   0   0   0   1   0]\n [  0   0   0   0   0   0   0  10   0   0   0   0]\n [  0   0   0   0   0   0   0   0  25   0   7   0]\n [  0   0   0   0   0   0   0   0   0  19   0   6]\n [  0   0   0   1   0   2   0   0  12   0  34   0]\n [  0   0   0   0   0   0   0   0   0   8   3  16]]\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X_train = pd.read_csv(\"X_train2.txt\", sep=\" \", header=None)\n",
    "y_train = pd.read_csv(\"y_train2.txt\", header=None)\n",
    "X_test = pd.read_csv(\"X_test2.txt\", sep=\" \", header=None)\n",
    "y_test = pd.read_csv(\"y_test2.txt\", header=None)\n",
    "\n",
    "kernels = ['Polynomial', 'RBF', 'Sigmoid','Linear']#A function which returns the corresponding SVC model\n",
    "def getClassifier(ktype):\n",
    "    if ktype == 0:\n",
    "        # Polynomial kernal\n",
    "        return SVC(kernel='poly', degree=8, gamma=\"auto\")\n",
    "    elif ktype == 1:\n",
    "        # Radial Basis Function kernal\n",
    "        return SVC(kernel='rbf', gamma='scale', C=100)\n",
    "    elif ktype == 2:\n",
    "        # Sigmoid kernal\n",
    "        return SVC(kernel='sigmoid', gamma=\"auto\")\n",
    "    elif ktype == 3:\n",
    "        # Linear kernal\n",
    "        return SVC(kernel='linear', gamma=\"auto\")\n",
    "\n",
    "for i in range(4):\n",
    "    svclassifier = getClassifier(i) \n",
    "    svclassifier.fit(X_train, y_train)# Make prediction\n",
    "    y_pred = svclassifier.predict(X_test)# Evaluate our model\n",
    "    print(\"Evaluation:\", kernels[i], \"kernel\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "param_grid = {'C':[1,10,100],'gamma':[1,0.1,0.001],'kernel': ['rbf']}\n",
    "\n",
    "grid = GridSearchCV(SVC(),param_grid,refit = True, verbose=2, n_jobs=2 , cv=10, return_train_score=True, scoring='accuracy')\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "predic = grid.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,predic))\n",
    "print(confusion_matrix(y_test, predic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}